{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Original raw data comes in CSV format, every year of data in a separate file. In this module, we construct schema that adheres to [Frictionless Data specificaitons](https://frictionlessdata.io/specs/), validate each table and erase problematic entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data\n",
    "\n",
    "Create symlinks from data location to \"./in\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Convert to UTF-8\n",
    "\n",
    "Original data come in unknown encoding. Make best guess and save in UTF-8.\n",
    "\n",
    "### Validate against schema\n",
    "\n",
    "[Schema spec](https://frictionlessdata.io/specs/table-schema/)\n",
    "\n",
    "That code is in a separate repo, and is possibly outdated. For now download validated and cleaned files from GCS.\n",
    "\n",
    "```\n",
    "mkdir -p data/csv\n",
    "gsutil -m cp -r gs://info-group-corr/*.csv data/csv/\n",
    "```\n",
    "\n",
    "The last 2 years (2016 and 2017) are missing.\n",
    "\n",
    "The schema is a separate JSON file, and can be used to assign correct data types when importing into BigQuery, Stata, pandas or any other dtype aware format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notest\n",
    "# hide\n",
    "\n",
    "# Separate schemas into separate files, one file per year.\n",
    "# Some columns are missing in certain years, and this is captured in \"field_lists\" fields of the JSON schema.\n",
    "\n",
    "import json\n",
    "\n",
    "def make_schema(y):\n",
    "    '''Prepare year-specific schema.'''\n",
    "    with open('data/csv/schema.json') as f:\n",
    "        schema = json.load(f)\n",
    "    for fl in schema['field_lists']:\n",
    "        if y in fl['years']:\n",
    "            used_fields = fl['fields']\n",
    "            break\n",
    "    new_fields = []\n",
    "    for f in schema['fields']:\n",
    "        if f['name'] in used_fields:\n",
    "            new_fields.append(f)\n",
    "    schema['fields'] = new_fields\n",
    "    del schema['field_lists']\n",
    "    return schema\n",
    "\n",
    "for y in range(1997, 2016):\n",
    "    with open(f'data/csv/{y}_schema.json', 'w') as f:\n",
    "        json.dump(make_schema(y), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracts\n",
    "\n",
    "It is handy to have smaller files for testing. Multiple approaches can be used to extract subsets in longitudinal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First 100k records\n",
    "\n",
    "This is probably unneccessary, because `pd.read_csv(nrows=100000)` does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    " \n",
    "def extract_100k():\n",
    "    \"\"\"Create extract with header and first 100k records.\"\"\"\n",
    "    dir_in = Path('./out/valid')\n",
    "    dir_out = Path('./out/extracts/100k')\n",
    "    for fn_in in dir_in.glob('*.csv'):\n",
    "        fn_out = dir_out / fn_in.name\n",
    "        with open(fn_out, 'w') as fout:\n",
    "            subprocess.run(['head', '-n', '100001', fn_in], stdout=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notest\n",
    "extract_100k()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
